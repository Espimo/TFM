# combined_script.py

import pandas as pd
from langdetect import detect
from multiprocessing import Pool

# Utility functions
def create_job_id_mapping(dataframe):
    dataframe = dataframe.copy()
    dataframe['job_id'] = range(1, len(dataframe) + 1)
    return dataframe[['job_link', 'job_id']]

def merge_datasets(df1, df2, on='job_link'):
    return df1.merge(df2, on=on, how='inner')

def detect_language(text):
    try:
        return detect(text)
    except:
        return 'unknown'

def detect_language_in_parallel(text_series):
    with Pool() as pool:
        languages = pool.map(detect_language, text_series)
    return languages

def filter_datasets_by_job_ids(df, job_ids):
    return df[df['job_id'].isin(job_ids)]

def filter_by_job_skills(df_postings_or_summaries, df_skills):
    valid_job_ids = df_skills['job_id'].unique()
    return df_postings_or_summaries[df_postings_or_summaries['job_id'].isin(valid_job_ids)]

def save_job_link_id(df, filename):
    df.to_csv(filename, index=False)

def drop_columns(df, columns_list):
    return df.drop(columns=columns_list)

def drop_null_rows(df):
    return df.dropna()

def combine_onet_skills(list_of_skill_dataframes):
    combined_df = pd.concat(list_of_skill_dataframes, ignore_index=True)
    combined_df.drop_duplicates(subset=['Skill'], inplace=True)
    combined_df.reset_index(drop=True, inplace=True)
    return combined_df

# Script starts here
if __name__ == "__main__":
    # Step 1: Create job_id mapping and merge datasets
    print("Starting Step 1: Creating job_id mapping and merging datasets...")
    linkedin_job_postings = pd.read_csv('linkedin_job_postings.csv')
    linkedin_job_summary = pd.read_csv('linkedin_job_summary.csv')
    linkedin_job_skills = pd.read_csv('linkedin_job_skills.csv')
    
    job_link_to_id = create_job_id_mapping(linkedin_job_postings)
    job_summary_with_id = merge_datasets(linkedin_job_summary, job_link_to_id)
    job_skills_with_id = merge_datasets(linkedin_job_skills, job_link_to_id)
    
    linkedin_job_postings.to_csv('job_postings_with_id.csv', index=False)
    job_summary_with_id.to_csv('job_summary_with_id.csv', index=False)
    job_skills_with_id.to_csv('job_skills_with_id.csv', index=False)
    print("Step 1 complete.")
    
    # Step 2: Detect language and save English summaries
    print("Starting Step 2: Detecting language and filtering English summaries...")
    job_summary_with_id = pd.read_csv('job_summary_with_id.csv')
    job_summary_with_id['job_summary_language'] = detect_language_in_parallel(job_summary_with_id['job_summary'])
    english_job_summaries = job_summary_with_id[job_summary_with_id['job_summary_language'] == 'en']
    english_job_summaries.to_csv('english_job_summaries.csv', index=False)
    print("Step 2 complete.")
    
    # Step 3: Filter datasets by job_ids
    print("Starting Step 3: Filtering datasets by job_ids...")
    english_job_summaries = pd.read_csv('english_job_summaries.csv')
    job_ids = english_job_summaries['job_id'].unique()
    
    job_postings_with_id = pd.read_csv('job_postings_with_id.csv')
    job_skills_with_id = pd.read_csv('job_skills_with_id.csv')
    
    filtered_job_postings = filter_datasets_by_job_ids(job_postings_with_id, job_ids)
    filtered_job_skills = filter_datasets_by_job_ids(job_skills_with_id, job_ids)
    
    filtered_job_postings.to_csv('filtered_job_postings.csv', index=False)
    filtered_job_skills.to_csv('filtered_job_skills.csv', index=False)
    print("Step 3 complete.")
    
    # Step 4: Remove records with missing skills
    print("Starting Step 4: Removing records with missing skills...")
    filtered_job_postings = pd.read_csv('filtered_job_postings.csv')
    filtered_job_skills = pd.read_csv('filtered_job_skills.csv')
    english_job_summaries = pd.read_csv('english_job_summaries.csv')
    
    final_job_postings = filter_by_job_skills(filtered_job_postings, filtered_job_skills)
    final_job_summaries = filter_by_job_skills(english_job_summaries, filtered_job_skills)
    
    final_job_postings.to_csv('final_job_postings.csv', index=False)
    final_job_summaries.to_csv('final_job_summaries.csv', index=False)
    print("Step 4 complete.")
    
    # Step 5: Save sorted job_id and job_link
    print("Starting Step 5: Saving sorted job_id and job_link...")
    sorted_job_skills = filtered_job_skills[['job_id', 'job_link']].sort_values(by='job_id')
    save_job_link_id(sorted_job_skills, 'sorted_job_skills.csv')
    print("Step 5 complete.")
    
    # Step 6: Drop unnecessary columns from job summaries
    print("Starting Step 6: Dropping unnecessary columns from job summaries...")
    final_job_summaries = pd.read_csv('final_job_summaries.csv')
    cleaned_job_summaries = drop_columns(final_job_summaries, ['job_summary_language', 'job_link'])
    cleaned_job_summaries.to_csv('cleaned_job_summaries.csv', index=False)
    print("Step 6 complete.")
    
    # Step 7: Remove null values from job skills
    print("Starting Step 7: Removing null values from job skills...")
    cleaned_job_skills = drop_null_rows(filtered_job_skills)
    cleaned_job_skills.to_csv('cleaned_job_skills.csv', index=False)
    print("Step 7 complete.")
    
    # Step 8: Ensure consistency among datasets
    print("Starting Step 8: Ensuring consistency among datasets...")
    valid_job_ids = cleaned_job_skills['job_id'].unique()
    
    consistent_job_summaries = filter_datasets_by_job_ids(cleaned_job_summaries, valid_job_ids)
    final_job_postings = pd.read_csv('final_job_postings.csv')
    consistent_job_postings = filter_datasets_by_job_ids(final_job_postings, valid_job_ids)
    
    consistent_job_summaries.to_csv('consistent_job_summaries.csv', index=False)
    consistent_job_postings.to_csv('consistent_job_postings.csv', index=False)
    print("Step 8 complete.")
    
    # Step 9: Merge datasets into a single one
    print("Starting Step 9: Merging datasets into a single dataset...")
    merged_data = merge_datasets(consistent_job_postings, cleaned_job_skills, on='job_id')
    merged_data = merge_datasets(merged_data, consistent_job_summaries, on='job_id')
    merged_data = merged_data.sort_values(by='job_id')
    merged_data.to_csv('unified_dataset.csv', index=False)
    print("Step 9 complete.")
    
    # Step 10: Combine ONET skills
    print("Starting Step 10: Combining ONET skills...")
    abilities_df = pd.read_excel('ONET_Abilities.xlsx', usecols=['Element Name']).rename(columns={'Element Name': 'Skill'})
    skills_df = pd.read_excel('ONET_Skills.xlsx', usecols=['Element Name']).rename(columns={'Element Name': 'Skill'})
    tech_skills_df = pd.read_excel('ONET_Tech_Skills.xlsx', usecols=['Example']).rename(columns={'Example': 'Skill'})
    
    combined_skills_df = combine_onet_skills([abilities_df, skills_df, tech_skills_df])
    combined_skills_df.to_csv('onetlist.csv', index=False, encoding='utf-8')
    print("Step 10 complete.")
    
    print("Process complete: All steps have been executed and final files have been saved.")
