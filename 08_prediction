import os
import joblib
import pickle
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification
import tensorflow as tf

# Directory configuration
models_dir = 'models'
output_dir = 'output'
tfidf_skills_path = os.path.join(models_dir, 'tfidf_vectorizer_skills.pkl')
tfidf_summary_path = os.path.join(models_dir, 'tfidf_vectorizer_summary.pkl')

# Model paths
model_paths = {
    'mlp': os.path.join(models_dir, 'mlp_model_checkpoint.pkl'),
    'random_forest': os.path.join(models_dir, 'random_forest_model_checkpoint.pkl'),
    'svm': os.path.join(models_dir, 'svm_model_checkpoint.pkl'),
    'xgboost': os.path.join(models_dir, 'xgboost_model_checkpoint.pkl')
}

def create_or_load_vectorizers():
    """Creates or loads the TF-IDF vectorizers"""
    if os.path.exists(tfidf_skills_path) and os.path.exists(tfidf_summary_path):
        with open(tfidf_skills_path, 'rb') as f:
            tfidf_vectorizer_skills = pickle.load(f)
        with open(tfidf_summary_path, 'rb') as f:
            tfidf_vectorizer_summary = pickle.load(f)
        print("TF-IDF vectorizers loaded.")
    else:
        print("Generating new TF-IDF vectorizers...")
        df = pd.read_csv('dataset_ready.csv')
        df['onet_skills'] = df['onet_skills'].apply(eval)
        
        tfidf_vectorizer_skills = TfidfVectorizer(max_features=10000, stop_words='english')
        tfidf_vectorizer_summary = TfidfVectorizer(max_features=10000, stop_words='english')
        
        tfidf_vectorizer_skills.fit(df['onet_skills'].apply(' '.join))
        tfidf_vectorizer_summary.fit(df['job_summary'])
        
        # Save vectorizers
        os.makedirs(models_dir, exist_ok=True)
        with open(tfidf_skills_path, 'wb') as f:
            pickle.dump(tfidf_vectorizer_skills, f)
        with open(tfidf_summary_path, 'wb') as f:
            pickle.dump(tfidf_vectorizer_summary, f)
        print("TF-IDF vectorizers generated and saved.")
    
    return tfidf_vectorizer_skills, tfidf_vectorizer_summary

def load_models():
    """Loads all ML models"""
    models = {}
    for model_name, path in model_paths.items():
        try:
            if model_name == 'xgboost':
                with open(path, 'rb') as f:
                    model = pickle.load(f)
                models[model_name] = model
                print(f"Model {model_name} loaded from {path}.")
            else:
                model = joblib.load(path)
                models[model_name] = model
                print(f"Model {model_name} loaded from {path}.")
        except Exception as e:
            print(f"Error loading the model {model_name}: {str(e)}")
    print("ML models loaded.")
    return models

def get_index_to_skill_mapping(skills_binarized_csv_path):
    """Obtains the mapping from index to skill name from the binarized CSV file."""
    skills_df = pd.read_csv(skills_binarized_csv_path)
    # Exclude the 'job_id' column if present
    skill_columns = [col for col in skills_df.columns if col != 'job_id']
    index_to_skill = {index: skill for index, skill in enumerate(skill_columns)}
    return index_to_skill

def make_predictions(examples, models, tfidf_vectorizer_summary, tokenizer, distilbert_model, index_to_skill):
    """Makes predictions using all available models and displays the skill names"""
    # Vectorize the examples
    tfidf_summary_vectors = tfidf_vectorizer_summary.transform(examples)
    
    # Predictions with ML models
    predictions = {}
    for model_name, model in models.items():
        print(f"\nPredictions with {model_name}:")
        try:
            if model_name == 'xgboost':
                # Initialize array to store predictions
                n_samples = tfidf_summary_vectors.shape[0]
                n_skills = sum([end_idx - start_idx for start_idx, end_idx, _ in model])
                xgb_preds = np.zeros((n_samples, n_skills))
                skill_idx = 0
                
                for start_idx, end_idx, submodel in model:
                    batch_pred = submodel.predict(tfidf_summary_vectors)
                    batch_size = end_idx - start_idx
                    xgb_preds[:, skill_idx:skill_idx+batch_size] = batch_pred
                    skill_idx += batch_size
                predicted_skills = np.where(xgb_preds > 0.5, 1, 0)
                predictions[model_name] = predicted_skills
            elif isinstance(model, list):  # Batch training case for other models
                pred_batch = np.zeros((tfidf_summary_vectors.shape[0], len(model)))
                for i, submodel in enumerate(model):
                    submodel_pred = submodel.predict(tfidf_summary_vectors)
                    if submodel_pred.ndim == 1:
                        pred_batch[:, i] = submodel_pred
                    else:
                        pred_batch[:, i] = submodel_pred[:, 0]
                predicted_skills = pred_batch
                predictions[model_name] = predicted_skills
            else:  # Single model case
                # Check if the model has the predict method
                if hasattr(model, 'predict'):
                    preds = model.predict(tfidf_summary_vectors)
                    if isinstance(preds, np.ndarray):
                        if preds.ndim == 1:
                            predicted_skills = np.where(preds > 0.5, 1, 0).reshape(-1, 1)
                        else:
                            predicted_skills = np.where(preds > 0.5, 1, 0)
                        predictions[model_name] = predicted_skills
                    else:
                        print(f"The predictions from {model_name} are not in the expected format")
                else:
                    print(f"The model {model_name} does not have a predict method")
                    continue  # Move to the next model

            # Display the predicted skill names
            for i, sample_preds in enumerate(predicted_skills):
                skill_indices = np.where(sample_preds == 1)[0]
                skill_names = [index_to_skill[idx] for idx in skill_indices]
                print(f"Example {i+1}")
                print(f"Skills predicted by {model_name}: {skill_names}\n")

        except Exception as e:
            print(f"Error making predictions with {model_name}: {str(e)}")
            continue

    # Predictions with DistilBERT
    print("\nPredictions with DistilBERT:")
    for i, text in enumerate(examples):
        try:
            inputs = tokenizer(
                text,
                truncation=True,
                padding='max_length',
                max_length=128,
                return_tensors='tf'
            )
            logits = distilbert_model(inputs).logits
            preds = tf.sigmoid(logits).numpy()[0]
            skill_indices = [i for i, pred in enumerate(preds) if pred >= 0.5]
            skill_names = [index_to_skill[idx] for idx in skill_indices]
            print(f"Example {i+1}")
            print(f"Skills predicted by DistilBERT: {skill_names}\n")
        except Exception as e:
            print(f"Error making predictions with DistilBERT: {str(e)}")
        
    return predictions

def main():
    # Load vectorizers
    tfidf_vectorizer_skills, tfidf_vectorizer_summary = create_or_load_vectorizers()
    
    # Load ML models
    models = load_models()
    
    # Load tokenizer and DistilBERT model
    try:
        tokenizer = DistilBertTokenizerFast.from_pretrained(models_dir + '/distilbert')
        distilbert_model = TFDistilBertForSequenceClassification.from_pretrained(models_dir + '/distilbert')
        print("DistilBERT model loaded successfully.")
    except Exception as e:
        print(f"Error loading DistilBERT: {str(e)}")
        return

    # Get the index-to-skill mapping from the binarized CSV
    skills_binarized_csv_path = 'dataset_skills_binarized.csv'  # Adjust path if needed
    index_to_skill = get_index_to_skill_mapping(skills_binarized_csv_path)
    
    # Example texts for prediction
    examples = [
        """...""",  # Example 1 text
        """..."""   # Example 2 text
    ]

    # Make predictions
    predictions = make_predictions(examples, models, tfidf_vectorizer_summary, tokenizer, distilbert_model, index_to_skill)

if __name__ == "__main__":
    main()
